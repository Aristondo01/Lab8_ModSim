{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 8\n",
    "Sebastian Aristondo 20880  \n",
    "Daniel Gonzlaez 20293"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simpy\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros de la simulación\n",
    "tiempo_simulacion = 3600  # Tiempo de simulación en segundos\n",
    "tasa_llegada_solicitudes = 40  # Tasa de llegada de solicitudes al sistema (solicitudes por segundo)\n",
    "tasa_atencion_servidor = 10  # Tasa de atención del servidor (solicitudes por segundo)\n",
    "\n",
    "# Variables para almacenar métricas\n",
    "solicitudes_atendidas_por_servidor = 0  # Inicialmente, el servidor no ha atendido ninguna solicitud\n",
    "tiempo_servidor_ocupado = 0  # Tiempo que estuvo el servidor ocupado\n",
    "tiempo_servidor_desocupado = 0  # Tiempo que estuvo el servidor desocupado\n",
    "tiempo_total_solicitudes_en_cola = []  # Tiempo total que las solicitudes estuvieron en cola\n",
    "total_solicitudes_en_cola = 1\n",
    "ultimo_momento_salida_solicitud = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso para simular la llegada de solicitudes\n",
    "def llegada_solicitudes(env, tasa_llegada, servidor):\n",
    "    solicitud_id = 0\n",
    "    while True:\n",
    "        arrival = env.now\n",
    "        yield env.timeout(np.random.exponential(1.0/tasa_llegada))\n",
    "        solicitud_id += 1\n",
    "        env.process(atender_solicitud(env, solicitud_id, servidor, arrival))\n",
    "\n",
    "# Proceso para simular el proceso de atención de una solicitud por el servidor\n",
    "def atender_solicitud(env, solicitud_id, servidor, arrival):\n",
    "    llegada_solicitud = env.now\n",
    "    # print(f\"Llegada de solicitud {solicitud_id} en el tiempo {llegada_solicitud}\")\n",
    "    # Calcular tiempo de atención\n",
    "    tiempo_atencion = np.random.exponential(1.0/tasa_atencion_servidor)\n",
    "\n",
    "    # Registrar tiempo en que el servidor se ocupó\n",
    "    global tiempo_servidor_ocupado\n",
    "    tiempo_servidor_ocupado += tiempo_atencion\n",
    "    \n",
    "    # Atender la solicitud\n",
    "    # print(f\"arrival:{arrival}, tiempo_atencion:{tiempo_atencion}, tiempo_servidor_ocupado:{tiempo_servidor_ocupado}\")\n",
    "    with servidor.request() as solicitud:\n",
    "        yield solicitud\n",
    "        tiempo_total_solicitudes_en_cola.append(env.now - llegada_solicitud)\n",
    "        yield env.timeout(tiempo_atencion)\n",
    "\n",
    "\n",
    "    # Incrementar el contador de solicitudes atendidas por el servidor\n",
    "    global solicitudes_atendidas_por_servidor\n",
    "    solicitudes_atendidas_por_servidor += 1\n",
    "    ultimo_momento_salida_solicitud = env.now\n",
    "    # print(f\"Atendiendo solicitud {solicitud_id} en el tiempo {env.now}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mountain Mega Computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Métricas finales:\n",
      "a. Solicitudes atendidas por el servidor: 143788\n",
      "b. Tiempo total en que el servidor estuvo ocupado: 1443.0704766173947\n",
      "c. Tiempo total en que el servidor estuvo desocupado: 2156.929523382605\n",
      "d. Tiempo total que las solicitudes estuvieron en cola: 975.716628006596\n",
      "e. Promedio de tiempo que cada solicitud estuvo en cola: 0.006785800122448299\n",
      "f. Promedio de solicitudes en cola por segundo: 0.0002777777777777778\n",
      "g. Momento de salida de la última solicitud: 3600\n"
     ]
    }
   ],
   "source": [
    "# Parámetros de la simulación\n",
    "tiempo_simulacion = 3600  # Tiempo de simulación en segundos\n",
    "tasa_llegada_solicitudes = 40  # Tasa de llegada de solicitudes al sistema (solicitudes por segundo)\n",
    "tasa_atencion_servidor = 100  # Tasa de atención del servidor (solicitudes por segundo)\n",
    "\n",
    "# Variables para almacenar métricas\n",
    "solicitudes_atendidas_por_servidor = 0  # Inicialmente, el servidor no ha atendido ninguna solicitud\n",
    "tiempo_servidor_ocupado = 0  # Tiempo que estuvo el servidor ocupado\n",
    "tiempo_servidor_desocupado = 0  # Tiempo que estuvo el servidor desocupado\n",
    "tiempo_total_solicitudes_en_cola = []  # Tiempo total que las solicitudes estuvieron en cola\n",
    "total_solicitudes_en_cola = 1\n",
    "\n",
    "\n",
    "# Inicializar la simulación\n",
    "env = simpy.Environment()\n",
    "\n",
    "# Crear el servidor\n",
    "servidor = simpy.Resource(env, capacity=1)\n",
    "\n",
    "# Iniciar el proceso de llegada de solicitudes\n",
    "env.process(llegada_solicitudes(env, tasa_llegada_solicitudes, servidor))\n",
    "\n",
    "# Ejecutar la simulación\n",
    "env.run(until=tiempo_simulacion)\n",
    "\n",
    "# Calcular métricas finales\n",
    "tiempo_total_simulacion = tiempo_simulacion * 1.0\n",
    "tiempo_total_solicitudes_en_cola = sum(tiempo_total_solicitudes_en_cola)\n",
    "promedio_tiempo_en_cola = tiempo_total_solicitudes_en_cola / solicitudes_atendidas_por_servidor\n",
    "promedio_solicitudes_en_cola_por_segundo = total_solicitudes_en_cola / tiempo_total_simulacion\n",
    "ultimo_momento_salida_solicitud = env.now\n",
    "tiempo_servidor_desocupado = tiempo_total_simulacion - tiempo_servidor_ocupado\n",
    "\n",
    "\n",
    "# Mostrar métricas finales\n",
    "print(\"\\nMétricas finales:\")\n",
    "print(f\"a. Solicitudes atendidas por el servidor: {solicitudes_atendidas_por_servidor}\")\n",
    "print(f\"b. Tiempo total en que el servidor estuvo ocupado: {tiempo_servidor_ocupado}\")\n",
    "print(f\"c. Tiempo total en que el servidor estuvo desocupado: {tiempo_servidor_desocupado}\")\n",
    "print(f\"d. Tiempo total que las solicitudes estuvieron en cola: {tiempo_total_solicitudes_en_cola}\")\n",
    "print(f\"e. Promedio de tiempo que cada solicitud estuvo en cola: {promedio_tiempo_en_cola}\")\n",
    "print(f\"f. Promedio de solicitudes en cola por segundo: {promedio_solicitudes_en_cola_por_segundo}\")\n",
    "print(f\"g. Momento de salida de la última solicitud: {ultimo_momento_salida_solicitud}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pizzita computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Métricas finales:\n",
      "a. Solicitudes atendidas por el servidor: 144244\n",
      "b. Tiempo total en que el servidor estuvo ocupado: 1439.2687704563648\n",
      "c. Tiempo total en que el servidor estuvo desocupado: 2160.731229543635\n",
      "d. Tiempo total que las solicitudes estuvieron en cola: 2.03546035592852\n",
      "e. Promedio de tiempo que cada solicitud estuvo en cola: 1.4111230664211475e-05\n",
      "f. Promedio de solicitudes en cola por segundo: 0.0002777777777777778\n",
      "g. Momento de salida de la última solicitud: 3600\n"
     ]
    }
   ],
   "source": [
    "# Parámetros de la simulación\n",
    "tiempo_simulacion = 3600  # Tiempo de simulación en segundos\n",
    "tasa_llegada_solicitudes = 40  # Tasa de llegada de solicitudes al sistema (solicitudes por segundo)\n",
    "tasa_atencion_servidor = 10  # Tasa de atención del servidor (solicitudes por segundo)\n",
    "\n",
    "# Variables para almacenar métricas\n",
    "solicitudes_atendidas_por_servidor = 0  # Inicialmente, el servidor no ha atendido ninguna solicitud\n",
    "tiempo_servidor_ocupado = 0  # Tiempo que estuvo el servidor ocupado\n",
    "tiempo_servidor_desocupado = 0  # Tiempo que estuvo el servidor desocupado\n",
    "tiempo_total_solicitudes_en_cola = []  # Tiempo total que las solicitudes estuvieron en cola\n",
    "total_solicitudes_en_cola = 1\n",
    "capacidad = 10\n",
    "ultimo_momento_salida_solicitud = 0\n",
    "\n",
    "# Inicializar la simulación\n",
    "env2 = simpy.Environment()\n",
    "\n",
    "# Crear el servidor\n",
    "servidor2 = simpy.Resource(env2, capacity=capacidad)\n",
    "\n",
    "# Iniciar el proceso de llegada de solicitudes\n",
    "env2.process(llegada_solicitudes(env2, tasa_llegada_solicitudes, servidor2))\n",
    "\n",
    "# Ejecutar la simulación\n",
    "env2.run(until=tiempo_simulacion)\n",
    "\n",
    "# Calcular métricas finales\n",
    "tiempo_total_simulacion = tiempo_simulacion * 1.0\n",
    "tiempo_total_solicitudes_en_cola = sum(tiempo_total_solicitudes_en_cola) / capacidad\n",
    "promedio_tiempo_en_cola = tiempo_total_solicitudes_en_cola / solicitudes_atendidas_por_servidor\n",
    "promedio_solicitudes_en_cola_por_segundo = total_solicitudes_en_cola / tiempo_total_simulacion\n",
    "ultimo_momento_salida_solicitud = env2.now\n",
    "tiempo_servidor_ocupado = tiempo_servidor_ocupado / capacidad\n",
    "tiempo_servidor_desocupado = ultimo_momento_salida_solicitud - tiempo_servidor_ocupado\n",
    "\n",
    "\n",
    "# Mostrar métricas finales\n",
    "print(\"\\nMétricas finales:\")\n",
    "print(f\"a. Solicitudes atendidas por el servidor: {solicitudes_atendidas_por_servidor}\")\n",
    "print(f\"b. Tiempo total en que el servidor estuvo ocupado: {tiempo_servidor_ocupado}\")\n",
    "print(f\"c. Tiempo total en que el servidor estuvo desocupado: {tiempo_servidor_desocupado}\")\n",
    "print(f\"d. Tiempo total que las solicitudes estuvieron en cola: {tiempo_total_solicitudes_en_cola}\")\n",
    "print(f\"e. Promedio de tiempo que cada solicitud estuvo en cola: {promedio_tiempo_en_cola}\")\n",
    "print(f\"f. Promedio de solicitudes en cola por segundo: {promedio_solicitudes_en_cola_por_segundo}\")\n",
    "print(f\"g. Momento de salida de la última solicitud: {ultimo_momento_salida_solicitud}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Métricas finales:\n",
      "a. Solicitudes atendidas por el servidor: 144778\n",
      "b. Tiempo total en que el servidor estuvo ocupado: 906.7595614245647\n",
      "c. Tiempo total en que el servidor estuvo desocupado: 2693.2404385754353\n",
      "d. Tiempo total que las solicitudes estuvieron en cola: 0.0\n",
      "e. Promedio de tiempo que cada solicitud estuvo en cola: 0.0\n",
      "f. Promedio de solicitudes en cola por segundo: 0.0002777777777777778\n",
      "g. Momento de salida de la última solicitud: 3600\n"
     ]
    }
   ],
   "source": [
    "# Parámetros de la simulación\n",
    "tiempo_simulacion = 3600  # Tiempo de simulación en segundos\n",
    "tasa_llegada_solicitudes = 40  # Tasa de llegada de solicitudes al sistema (solicitudes por segundo)\n",
    "tasa_atencion_servidor = 10  # Tasa de atención del servidor (solicitudes por segundo)\n",
    "\n",
    "# Variables para almacenar métricas\n",
    "solicitudes_atendidas_por_servidor = 0  # Inicialmente, el servidor no ha atendido ninguna solicitud\n",
    "tiempo_servidor_ocupado = 0  # Tiempo que estuvo el servidor ocupado\n",
    "tiempo_servidor_desocupado = 0  # Tiempo que estuvo el servidor desocupado\n",
    "tiempo_total_solicitudes_en_cola = []  # Tiempo total que las solicitudes estuvieron en cola\n",
    "total_solicitudes_en_cola = 1\n",
    "capacidad = 16\n",
    "ultimo_momento_salida_solicitud = 0\n",
    "\n",
    "# Inicializar la simulación\n",
    "env2 = simpy.Environment()\n",
    "\n",
    "# Crear el servidor\n",
    "servidor2 = simpy.Resource(env2, capacity=capacidad)\n",
    "\n",
    "# Iniciar el proceso de llegada de solicitudes\n",
    "env2.process(llegada_solicitudes(env2, tasa_llegada_solicitudes, servidor2))\n",
    "\n",
    "# Ejecutar la simulación\n",
    "env2.run(until=tiempo_simulacion)\n",
    "\n",
    "# Calcular métricas finales\n",
    "tiempo_total_simulacion = tiempo_simulacion * 1.0\n",
    "tiempo_total_solicitudes_en_cola = sum(tiempo_total_solicitudes_en_cola) / capacidad\n",
    "promedio_tiempo_en_cola = tiempo_total_solicitudes_en_cola / solicitudes_atendidas_por_servidor\n",
    "promedio_solicitudes_en_cola_por_segundo = total_solicitudes_en_cola / tiempo_total_simulacion\n",
    "ultimo_momento_salida_solicitud = env2.now\n",
    "tiempo_servidor_ocupado = tiempo_servidor_ocupado / capacidad\n",
    "tiempo_servidor_desocupado = ultimo_momento_salida_solicitud - tiempo_servidor_ocupado\n",
    "\n",
    "\n",
    "# Mostrar métricas finales\n",
    "print(\"\\nMétricas finales:\")\n",
    "print(f\"a. Solicitudes atendidas por el servidor: {solicitudes_atendidas_por_servidor}\")\n",
    "print(f\"b. Tiempo total en que el servidor estuvo ocupado: {tiempo_servidor_ocupado}\")\n",
    "print(f\"c. Tiempo total en que el servidor estuvo desocupado: {tiempo_servidor_desocupado}\")\n",
    "print(f\"d. Tiempo total que las solicitudes estuvieron en cola: {tiempo_total_solicitudes_en_cola}\")\n",
    "print(f\"e. Promedio de tiempo que cada solicitud estuvo en cola: {promedio_tiempo_en_cola}\")\n",
    "print(f\"f. Promedio de solicitudes en cola por segundo: {promedio_solicitudes_en_cola_por_segundo}\")\n",
    "print(f\"g. Momento de salida de la última solicitud: {ultimo_momento_salida_solicitud}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se probó con distintas configuraciones de servers. Primero se probó muy holgadamente, con 100 servers y se encontró que aquí ya no esperaba ninguna solicitud. Luego, se probó con 50 y 20 y sucedió lo mismo. Con 15 si se esperaba y con 16, dejó de esperar. Así que, de forma empírica, la cantiad óptima de servidores que hacen que no haya congestión en el sistema es de 16."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mountain Mega Computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Métricas finales:\n",
      "a. Solicitudes atendidas por el servidor: 359571\n",
      "b. Tiempo total en que el servidor estuvo ocupado: 3599.732904948749\n",
      "c. Tiempo total en que el servidor estuvo desocupado: 0.2670950512510899\n",
      "d. Tiempo total que las solicitudes estuvieron en cola: 895636.9752671174\n",
      "e. Promedio de tiempo que cada solicitud estuvo en cola: 2.490848748278135\n",
      "f. Promedio de solicitudes en cola por segundo: 0.0002777777777777778\n",
      "g. Momento de salida de la última solicitud: 3600\n"
     ]
    }
   ],
   "source": [
    "# Parámetros de la simulación\n",
    "tiempo_simulacion = 3600  # Tiempo de simulación en segundos\n",
    "tasa_llegada_solicitudes = 100  # Tasa de llegada de solicitudes al sistema (solicitudes por segundo)\n",
    "tasa_atencion_servidor = 100  # Tasa de atención del servidor (solicitudes por segundo)\n",
    "\n",
    "# Variables para almacenar métricas\n",
    "solicitudes_atendidas_por_servidor = 0  # Inicialmente, el servidor no ha atendido ninguna solicitud\n",
    "tiempo_servidor_ocupado = 0  # Tiempo que estuvo el servidor ocupado\n",
    "tiempo_servidor_desocupado = 0  # Tiempo que estuvo el servidor desocupado\n",
    "tiempo_total_solicitudes_en_cola = []  # Tiempo total que las solicitudes estuvieron en cola\n",
    "total_solicitudes_en_cola = 1\n",
    "capacidad = 1\n",
    "ultimo_momento_salida_solicitud = 0\n",
    "\n",
    "# Inicializar la simulación\n",
    "env2 = simpy.Environment()\n",
    "\n",
    "# Crear el servidor\n",
    "servidor2 = simpy.Resource(env2, capacity=capacidad)\n",
    "\n",
    "# Iniciar el proceso de llegada de solicitudes\n",
    "env2.process(llegada_solicitudes(env2, tasa_llegada_solicitudes, servidor2))\n",
    "\n",
    "# Ejecutar la simulación\n",
    "env2.run(until=tiempo_simulacion)\n",
    "\n",
    "# Calcular métricas finales\n",
    "tiempo_total_simulacion = tiempo_simulacion * 1.0\n",
    "tiempo_total_solicitudes_en_cola = sum(tiempo_total_solicitudes_en_cola) / capacidad\n",
    "promedio_tiempo_en_cola = tiempo_total_solicitudes_en_cola / solicitudes_atendidas_por_servidor\n",
    "promedio_solicitudes_en_cola_por_segundo = total_solicitudes_en_cola / tiempo_total_simulacion\n",
    "ultimo_momento_salida_solicitud = env2.now\n",
    "tiempo_servidor_ocupado = tiempo_servidor_ocupado / capacidad\n",
    "tiempo_servidor_desocupado = ultimo_momento_salida_solicitud - tiempo_servidor_ocupado\n",
    "\n",
    "\n",
    "# Mostrar métricas finales\n",
    "print(\"\\nMétricas finales:\")\n",
    "print(f\"a. Solicitudes atendidas por el servidor: {solicitudes_atendidas_por_servidor}\")\n",
    "print(f\"b. Tiempo total en que el servidor estuvo ocupado: {tiempo_servidor_ocupado}\")\n",
    "print(f\"c. Tiempo total en que el servidor estuvo desocupado: {tiempo_servidor_desocupado}\")\n",
    "print(f\"d. Tiempo total que las solicitudes estuvieron en cola: {tiempo_total_solicitudes_en_cola}\")\n",
    "print(f\"e. Promedio de tiempo que cada solicitud estuvo en cola: {promedio_tiempo_en_cola}\")\n",
    "print(f\"f. Promedio de solicitudes en cola por segundo: {promedio_solicitudes_en_cola_por_segundo}\")\n",
    "print(f\"g. Momento de salida de la última solicitud: {ultimo_momento_salida_solicitud}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Métricas finales:\n",
      "a. Solicitudes atendidas por el servidor: 360498\n",
      "b. Tiempo total en que el servidor estuvo ocupado: 3589.389052065474\n",
      "c. Tiempo total en que el servidor estuvo desocupado: 10.610947934525939\n",
      "d. Tiempo total que las solicitudes estuvieron en cola: 66844.52802033506\n",
      "e. Promedio de tiempo que cada solicitud estuvo en cola: 0.18542274303972575\n",
      "f. Promedio de solicitudes en cola por segundo: 0.0002777777777777778\n",
      "g. Momento de salida de la última solicitud: 3600\n"
     ]
    }
   ],
   "source": [
    "# Parámetros de la simulación\n",
    "tiempo_simulacion = 3600  # Tiempo de simulación en segundos\n",
    "tasa_llegada_solicitudes = 100  # Tasa de llegada de solicitudes al sistema (solicitudes por segundo)\n",
    "tasa_atencion_servidor = 10  # Tasa de atención del servidor (solicitudes por segundo)\n",
    "\n",
    "# Variables para almacenar métricas\n",
    "solicitudes_atendidas_por_servidor = 0  # Inicialmente, el servidor no ha atendido ninguna solicitud\n",
    "tiempo_servidor_ocupado = 0  # Tiempo que estuvo el servidor ocupado\n",
    "tiempo_servidor_desocupado = 0  # Tiempo que estuvo el servidor desocupado\n",
    "tiempo_total_solicitudes_en_cola = []  # Tiempo total que las solicitudes estuvieron en cola\n",
    "total_solicitudes_en_cola = 1\n",
    "capacidad = 10\n",
    "ultimo_momento_salida_solicitud = 0\n",
    "\n",
    "# Inicializar la simulación\n",
    "env2 = simpy.Environment()\n",
    "\n",
    "# Crear el servidor\n",
    "servidor2 = simpy.Resource(env2, capacity=capacidad)\n",
    "\n",
    "# Iniciar el proceso de llegada de solicitudes\n",
    "env2.process(llegada_solicitudes(env2, tasa_llegada_solicitudes, servidor2))\n",
    "\n",
    "# Ejecutar la simulación\n",
    "env2.run(until=tiempo_simulacion)\n",
    "\n",
    "# Calcular métricas finales\n",
    "tiempo_total_simulacion = tiempo_simulacion * 1.0\n",
    "tiempo_total_solicitudes_en_cola = sum(tiempo_total_solicitudes_en_cola) / capacidad\n",
    "promedio_tiempo_en_cola = tiempo_total_solicitudes_en_cola / solicitudes_atendidas_por_servidor\n",
    "promedio_solicitudes_en_cola_por_segundo = total_solicitudes_en_cola / tiempo_total_simulacion\n",
    "ultimo_momento_salida_solicitud = env2.now\n",
    "tiempo_servidor_ocupado = tiempo_servidor_ocupado / capacidad\n",
    "tiempo_servidor_desocupado = ultimo_momento_salida_solicitud - tiempo_servidor_ocupado\n",
    "\n",
    "\n",
    "# Mostrar métricas finales\n",
    "print(\"\\nMétricas finales:\")\n",
    "print(f\"a. Solicitudes atendidas por el servidor: {solicitudes_atendidas_por_servidor}\")\n",
    "print(f\"b. Tiempo total en que el servidor estuvo ocupado: {tiempo_servidor_ocupado}\")\n",
    "print(f\"c. Tiempo total en que el servidor estuvo desocupado: {tiempo_servidor_desocupado}\")\n",
    "print(f\"d. Tiempo total que las solicitudes estuvieron en cola: {tiempo_total_solicitudes_en_cola}\")\n",
    "print(f\"e. Promedio de tiempo que cada solicitud estuvo en cola: {promedio_tiempo_en_cola}\")\n",
    "print(f\"f. Promedio de solicitudes en cola por segundo: {promedio_solicitudes_en_cola_por_segundo}\")\n",
    "print(f\"g. Momento de salida de la última solicitud: {ultimo_momento_salida_solicitud}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Búsqueda empírica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Métricas finales:\n",
      "a. Solicitudes atendidas por el servidor: 359453\n",
      "b. Tiempo total en que el servidor estuvo ocupado: 1240.0631749947258\n",
      "c. Tiempo total en que el servidor estuvo desocupado: 2359.936825005274\n",
      "d. Tiempo total que las solicitudes estuvieron en cola: 0.0\n",
      "e. Promedio de tiempo que cada solicitud estuvo en cola: 0.0\n",
      "f. Promedio de solicitudes en cola por segundo: 0.0002777777777777778\n",
      "g. Momento de salida de la última solicitud: 3600\n"
     ]
    }
   ],
   "source": [
    "# Parámetros de la simulación\n",
    "tiempo_simulacion = 3600  # Tiempo de simulación en segundos\n",
    "tasa_llegada_solicitudes = 100  # Tasa de llegada de solicitudes al sistema (solicitudes por segundo)\n",
    "tasa_atencion_servidor = 10  # Tasa de atención del servidor (solicitudes por segundo)\n",
    "\n",
    "# Variables para almacenar métricas\n",
    "solicitudes_atendidas_por_servidor = 0  # Inicialmente, el servidor no ha atendido ninguna solicitud\n",
    "tiempo_servidor_ocupado = 0  # Tiempo que estuvo el servidor ocupado\n",
    "tiempo_servidor_desocupado = 0  # Tiempo que estuvo el servidor desocupado\n",
    "tiempo_total_solicitudes_en_cola = []  # Tiempo total que las solicitudes estuvieron en cola\n",
    "total_solicitudes_en_cola = 1\n",
    "capacidad = 29\n",
    "ultimo_momento_salida_solicitud = 0\n",
    "\n",
    "# Inicializar la simulación\n",
    "env2 = simpy.Environment()\n",
    "\n",
    "# Crear el servidor\n",
    "servidor2 = simpy.Resource(env2, capacity=capacidad)\n",
    "\n",
    "# Iniciar el proceso de llegada de solicitudes\n",
    "env2.process(llegada_solicitudes(env2, tasa_llegada_solicitudes, servidor2))\n",
    "\n",
    "# Ejecutar la simulación\n",
    "env2.run(until=tiempo_simulacion)\n",
    "\n",
    "# Calcular métricas finales\n",
    "tiempo_total_simulacion = tiempo_simulacion * 1.0\n",
    "tiempo_total_solicitudes_en_cola = sum(tiempo_total_solicitudes_en_cola) / capacidad\n",
    "promedio_tiempo_en_cola = tiempo_total_solicitudes_en_cola / solicitudes_atendidas_por_servidor\n",
    "promedio_solicitudes_en_cola_por_segundo = total_solicitudes_en_cola / tiempo_total_simulacion\n",
    "ultimo_momento_salida_solicitud = env2.now\n",
    "tiempo_servidor_ocupado = tiempo_servidor_ocupado / capacidad\n",
    "tiempo_servidor_desocupado = ultimo_momento_salida_solicitud - tiempo_servidor_ocupado\n",
    "\n",
    "\n",
    "# Mostrar métricas finales\n",
    "print(\"\\nMétricas finales:\")\n",
    "print(f\"a. Solicitudes atendidas por el servidor: {solicitudes_atendidas_por_servidor}\")\n",
    "print(f\"b. Tiempo total en que el servidor estuvo ocupado: {tiempo_servidor_ocupado}\")\n",
    "print(f\"c. Tiempo total en que el servidor estuvo desocupado: {tiempo_servidor_desocupado}\")\n",
    "print(f\"d. Tiempo total que las solicitudes estuvieron en cola: {tiempo_total_solicitudes_en_cola}\")\n",
    "print(f\"e. Promedio de tiempo que cada solicitud estuvo en cola: {promedio_tiempo_en_cola}\")\n",
    "print(f\"f. Promedio de solicitudes en cola por segundo: {promedio_solicitudes_en_cola_por_segundo}\")\n",
    "print(f\"g. Momento de salida de la última solicitud: {ultimo_momento_salida_solicitud}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que con 29 servidores se pueden manejar las 6000 solicitudes por minuto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que la usar Pizzita computing, si se aumentan las solicitudes por minuto de una manera importante, la cantidad de servidores va a aumentar casi de forma lineal, si se quiere lograr que las solicitudes no esperen. Por lo tanto, es necesario considerar adecuadamente cuál es el precio de los servidores y cuál es la carga esperada en los años venideros. De forma que puede ser que no sea beneficioso de forma económica contratar a esta empresa. Sin embargo, si no es imprescindible que las solicitudes no esperen, probablmente sea mejor usar a Pizzita que a Mountain, porque la cantidad de requests que manejan es similar, pero el tiempo de espera en cola es mucho menor en Pizzita que en mountain. Por esto, es posible que aunque Pizzita tenga menor capacidad computacional, se compensa con el tiempo de espera. \n",
    "\n",
    "Además como esta planificando que en 2 años se llegara a esa cantidad de solicitudes, es mejor usar Pizzita, ya que se puede ir aumentando la cantidad de servidores de forma lineal, y no se tiene que pagar por servidores que no se estan usando. Eso permite que el crecimiento sea organico, sumandole que los tiempos de espera no aumentaran conforme aumenten las solicitudes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
